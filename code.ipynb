{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/nwzish/anaconda3/envs/fl/lib/python3.8/site-packages (4.61.1)\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install chromedriver-py\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter start_date and end_date\n",
    "START_DATE = '2021/06/15'\n",
    "END_DATE= '2021/06/18'\n",
    "#enter stock code upper limit\n",
    "STOCK_CODE_END = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_list(sd,ed):\n",
    "    _sd = datetime.strptime(sd, '%Y/%m/%d')\n",
    "    _ed = datetime.strptime(ed, '%Y/%m/%d')\n",
    "    \n",
    "    if _sd > _ed:\n",
    "        sys.exit(\"Start date is more than end date\")\n",
    "\n",
    "    _date_list = []\n",
    "    \n",
    "    while _sd<=_ed:\n",
    "        _date_list.append(_sd.strftime('%Y/%m/%d'))\n",
    "        _sd = _sd + timedelta(days=1)\n",
    "        \n",
    "    return _date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = get_date_list(START_DATE,END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_code_list(_date):\n",
    "    limit = STOCK_CODE_END\n",
    "    _date = _date.replace('/','')\n",
    "    list_URL = 'https://www.hkexnews.hk/sdw/search/stocklist.aspx?sortby=stockcode&shareholdingdate='+_date\n",
    "    driver2 = webdriver.Chrome(os.getcwd()+'/chromedriver',options=chrome_options)\n",
    "    driver2.get(list_URL)\n",
    "    soup = BeautifulSoup(driver2.page_source,'html.parser')\n",
    "    stock_table = soup.select_one('table').select_one('tbody').select('tr')\n",
    "    \n",
    "    _stock_list = []\n",
    "    for r in stock_table:\n",
    "        stock_code = r.select_one('td').get_text().replace('\\n','').strip()\n",
    "        \n",
    "        if int(stock_code)>limit:\n",
    "            break\n",
    "        _stock_list.append(stock_code)\n",
    "    driver2.close()\n",
    "    \n",
    "    return _stock_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_data(summary):\n",
    "    _summary_category = []\n",
    "    _shareholding = []\n",
    "    _number_of_participants = []\n",
    "    _percent_of_participants = []\n",
    "    summary_data = {}\n",
    "    for s in summary[0].select('div.ccass-search-datarow'):\n",
    "\n",
    "        sc = s.select_one('div.summary-category').get_text()\n",
    "        summary_data[sc] = []\n",
    "        _summary_category.append(sc)\n",
    "    #     print(sc)\n",
    "        sh = s.select_one('div.shareholding').select_one('.value').get_text()\n",
    "    #     print(sh)\n",
    "    #     print(int(sh.select_one('.value').get_text().replace(',','')))\n",
    "        _shareholding.append(sh)\n",
    "        summary_data[sc].append(sh)\n",
    "        nop = s.select_one('div.number-of-participants').select_one('.value').get_text()\n",
    "    #         print(e.select_one('.value').get_text())\n",
    "        _number_of_participants.append(nop)\n",
    "        summary_data[sc].append(nop)\n",
    "        pop = s.select_one('div.percent-of-participants').select_one('.value').get_text()\n",
    "    #     for e in pop[1:]:\n",
    "        _percent_of_participants.append(pop)\n",
    "        summary_data[sc].append(pop)\n",
    "    #         print(e.select_one('.value').get_text())\n",
    "    #     print(s.select('div.number-of-participants')[1].select('div.value')[0].get_text())\n",
    "    #     print(s)\n",
    "\n",
    "    luf = re.sub('\\s+',' ',summary[0].select_one('div.summary-header').get_text().replace('\\n','').strip())\n",
    "    _tluf = int(summary[0].select_one('div.summary-value').get_text().replace(',',''))\n",
    "    summary_data[luf] = _tluf\n",
    "\n",
    "#     print(luf)\n",
    "#     print(_summary_category)\n",
    "#     print(_shareholding)\n",
    "#     print(_number_of_participants)\n",
    "#     print(_percent_of_participants)\n",
    "#     print(_total_number_of_issued_shares)\n",
    "#     summary_data\n",
    "\n",
    "    for k in summary_data.keys():\n",
    "        summary_data[k] = [summary_data[k]]\n",
    "\n",
    "    return summary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_names(_table):\n",
    "    _column_name = []\n",
    "    for c in _table[0].select('th'):\n",
    "        _column_name.append(c.get_text().strip())\n",
    "    \n",
    "    return _column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_data(_table):\n",
    "    \n",
    "    \n",
    "    _participant_id = []\n",
    "    _name_of_ccass = []\n",
    "    _address = []\n",
    "    _shareholding = []\n",
    "    _percent_of_total_issued_shares = []\n",
    "    \n",
    "    for r in _table[1:]:\n",
    "\n",
    "        cells = r.select('td')\n",
    "        _participant_id.append(cells[0].select_one('div.mobile-list-body').get_text() or '')\n",
    "        _name_of_ccass.append(cells[1].select_one('div.mobile-list-body').get_text() or '')\n",
    "        _address.append(cells[2].select_one('div.mobile-list-body').get_text() or '')\n",
    "        _shareholding.append(cells[3].select_one('div.mobile-list-body').get_text() or '')\n",
    "        _percent_of_total_issued_shares.append(cells[4].select_one('div.mobile-list-body').get_text() or '') \n",
    "\n",
    "#     print(_participant_id)\n",
    "#     print(_name_of_ccass)\n",
    "#     print(_address)\n",
    "#     print(_shareholding)\n",
    "#     print(_percent_of_total_issued_shares)\n",
    "    tdl = [_participant_id,_name_of_ccass,_address,_shareholding,_percent_of_total_issued_shares]\n",
    "    tcn = get_column_names(_table)\n",
    "    \n",
    "    td = {}\n",
    "    for i in range(5):\n",
    "        td[tcn[i]] = tdl[i]\n",
    "    \n",
    "    return td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(soup):\n",
    "    \n",
    "    summary = soup.find_all('div',id='pnlResultSummary')\n",
    "    _summary_data = get_summary_data(summary)\n",
    "#     print(\"From extract: \",_summary_data)\n",
    "    table = soup.find_all('div',id='pnlResultNormal')[0].select('tr')\n",
    "    _table_data = get_table_data(table)\n",
    "#     print(\"From extract: \",_table_data)\n",
    "    return _summary_data,_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver(url):\n",
    "    _driver = webdriver.Chrome(os.getcwd()+'/chromedriver',options=chrome_options)\n",
    "    _driver.get(url)\n",
    "    \n",
    "    return _driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_df(sd,d,s):\n",
    "    path = 'summary/'+d.replace('/','')\n",
    "    os.makedirs(path,exist_ok=True)\n",
    "    df = pd.DataFrame(sd)\n",
    "    fn = path+'/'+s+'.csv'\n",
    "    df.to_csv(fn,index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_df(td,d,s):\n",
    "    path = 'table/'+d.replace('/','')\n",
    "    os.makedirs(path,exist_ok=True)\n",
    "    df = pd.DataFrame(td)\n",
    "    fn = path+'/'+s+'.csv'\n",
    "    df.to_csv(fn,index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scraping_index(data):\n",
    "    \n",
    "    json.dump(data,open(\"scraping_index.json\",\"w\"))\n",
    "\n",
    "def load_scarping_index():\n",
    "    data = json.load(open(\"scraping_index.json\"))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## don't run this cell if you want to resume the scarapping\n",
    "## uncomment the below code if you are starting the scrapping initially \n",
    "#data_scraped = {} \n",
    "#save_scraping_index(data_scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_list = []\n",
    "td_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching for date:  2021/06/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 114/184 [04:35<03:13,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soemthing went wrong in: 2021/06/15 00123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [07:27<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching for date:  2021/06/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 114/184 [04:38<02:20,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soemthing went wrong in: 2021/06/16 00123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [07:38<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching for date:  2021/06/17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 114/184 [04:59<02:10,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soemthing went wrong in: 2021/06/17 00123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [07:35<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching for date:  2021/06/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 114/184 [04:40<02:04,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soemthing went wrong in: 2021/06/18 00123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [07:26<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 30s, sys: 2.13 s, total: 5min 32s\n",
      "Wall time: 31min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# rerun the cell if some errors occurs to resume scrapping\n",
    "%%time\n",
    "URL = \"https://www.hkexnews.hk/sdw/search/searchsdw.aspx\"\n",
    "si = load_scarping_index()\n",
    "\n",
    "print(\"Scrapping upto Stock code: \", STOCK_CODE_END)\n",
    "for d in date_list:\n",
    "    print('Fetching for date: ',d)\n",
    "    driver = get_driver(URL)\n",
    "    stock_code_list = get_stock_code_list(d)\n",
    "    for s in tqdm(stock_code_list):\n",
    "        if not si.get(d,False):\n",
    "            si[d] = {}           \n",
    "        if not si[d].get(s,False):\n",
    "            try:\n",
    "                driver.execute_script(f\"document.getElementById('txtShareholdingDate').value='{d}'\")\n",
    "                driver.execute_script(f\"document.getElementById('txtStockCode').value='{s}'\")\n",
    "                driver.find_element_by_id('btnSearch').click()\n",
    "                soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "#                 print(f\"document.getElementById('txtShareholdingDate').value='{d}'\")\n",
    "                sd,td = extract_data(soup)\n",
    "#                 print(sd,td)\n",
    "                sd['Date'] = datetime.strptime(d, '%Y/%m/%d')\n",
    "                sd['Stock code'] = s\n",
    "                td['Date'] = datetime.strptime(d, '%Y/%m/%d')\n",
    "                td['Stock code'] = s\n",
    "                sd_list.append(sd)\n",
    "                td_list.append(td)\n",
    "                create_summary_df(sd,d,s)\n",
    "                create_table_df(td,d,s)\n",
    "                si[d][s] = True\n",
    "#                 print(f'fetched {d},{s}')\n",
    "                save_scraping_index(si)\n",
    "            except :\n",
    "                si[d][s] = False\n",
    "                save_scraping_index(si)\n",
    "                print(\"Soemthing went wrong in: \"+d+\" \"+s)\n",
    "            \n",
    "#         time.sleep(1)\n",
    "\n",
    "    driver.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_list(_dir):\n",
    "    dates = os.listdir(_dir)\n",
    "    dates.sort()\n",
    "    dw_fl = []\n",
    "#     print(dates)\n",
    "    for d in dates:\n",
    "        \n",
    "        fl = []\n",
    "        fns = os.listdir(f'{_dir}/{d}')\n",
    "        fns.sort()\n",
    "#         print(fns)\n",
    "        for fn in fns:\n",
    "            fl.append(f'{_dir}/{d}/{fn}')\n",
    "        dw_fl.append(fl)\n",
    "        \n",
    "    return dw_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_summary():\n",
    "    dw_fl = generate_file_list('summary') \n",
    "    for fl in dw_fl:\n",
    "        dfl = []\n",
    "        for fn in fl:\n",
    "            df = pd.read_csv(fn)\n",
    "            dfl.append(df)\n",
    "        dw_df = pd.concat(dfl).reset_index(drop=True)\n",
    "        columns = list(dw_df.columns)\n",
    "        dw_df = dw_df[columns[-2:]+columns[:-2]]\n",
    "        os.makedirs('_summary',exist_ok=True)\n",
    "        _fn = f'_summary/{fl[0].split(\"/\")[1]}.csv'\n",
    "        print(_fn)\n",
    "        dw_df.to_csv(_fn,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_table():\n",
    "    dw_fl = generate_file_list('table') \n",
    "    for fl in dw_fl:\n",
    "        dfl = []\n",
    "        for fn in fl:\n",
    "            df = pd.read_csv(fn)\n",
    "            dfl.append(df)\n",
    "            \n",
    "        dw_df = pd.concat(dfl).reset_index(drop=True)\n",
    "        cn = list(dw_df.columns)\n",
    "        \n",
    "        pot = dw_df[cn[:3]]\n",
    "        pot = pot.drop_duplicates(cn[0]).reset_index(drop=True)\n",
    "        \n",
    "        dw_df = dw_df[cn[-2:]+cn[:1]+cn[3:-2]]\n",
    "        print(cn)\n",
    "        os.makedirs('_table',exist_ok=True)\n",
    "        _fn = f'_table/{fl[0].split(\"/\")[1]}.csv'\n",
    "        print(_fn)\n",
    "        dw_df.to_csv(_fn,index=False)\n",
    "        \n",
    "        _fnp = f'_table/p_id_{fl[0].split(\"/\")[1]}.csv'\n",
    "        print(_fnp)\n",
    "        pot.to_csv(_fnp,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_failed_list():\n",
    "    si = load_scarping_index()\n",
    "    data=[]\n",
    "    for d in si.keys():\n",
    "#         print(d)\n",
    "        for k,v in si[d].items():\n",
    "            if not v:\n",
    "                data.append([d,k])\n",
    "\n",
    "    df=pd.DataFrame(data,columns=['Date','Stock code'])\n",
    "    df.to_csv(f'{START_DATE.replace(\"/\",\"\")}_{END_DATE.replace(\"/\",\"\")}_failed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_summary/20210615.csv\n",
      "_summary/20210616.csv\n",
      "_summary/20210617.csv\n",
      "_summary/20210618.csv\n",
      "['Participant ID', 'Name of CCASS Participant(* for Consenting Investor Participants )', 'Address', 'Shareholding', '% of the total number of Issued Shares/ Warrants/ Units', 'Date', 'Stock code']\n",
      "_table/20210615.csv\n",
      "_table/p_id_20210615.csv\n",
      "['Participant ID', 'Name of CCASS Participant(* for Consenting Investor Participants )', 'Address', 'Shareholding', '% of the total number of Issued Shares/ Warrants/ Units', 'Date', 'Stock code']\n",
      "_table/20210616.csv\n",
      "_table/p_id_20210616.csv\n",
      "['Participant ID', 'Name of CCASS Participant(* for Consenting Investor Participants )', 'Address', 'Shareholding', '% of the total number of Issued Shares/ Warrants/ Units', 'Date', 'Stock code']\n",
      "_table/20210617.csv\n",
      "_table/p_id_20210617.csv\n",
      "['Participant ID', 'Name of CCASS Participant(* for Consenting Investor Participants )', 'Address', 'Shareholding', '% of the total number of Issued Shares/ Warrants/ Units', 'Date', 'Stock code']\n",
      "_table/20210618.csv\n",
      "_table/p_id_20210618.csv\n"
     ]
    }
   ],
   "source": [
    "# run this cell to generate csv\n",
    "combine_summary()\n",
    "combine_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to generate failed list csv\n",
    "create_failed_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021/06/15</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021/06/16</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021/06/17</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021/06/18</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Stock code\n",
       "0  2021/06/15         123\n",
       "1  2021/06/16         123\n",
       "2  2021/06/17         123\n",
       "3  2021/06/18         123"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'{START_DATE.replace(\"/\",\"\")}_{END_DATE.replace(\"/\",\"\")}_failed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
